{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset we will be working with and reset index\n",
    "import pandas as pd\n",
    "players_df = pd.read_pickle(\"players_df.pkl\")\n",
    "players_df = players_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    1409802\n",
      "True      183348\n",
      "Name: stats.neutralMinionsKilledTeamJungle, dtype: int64\n",
      "False    1409802\n",
      "True      183348\n",
      "Name: stats.neutralMinionsKilledEnemyJungle, dtype: int64\n",
      "False    1409766\n",
      "True      183384\n",
      "Name: stats.wardsPlaced, dtype: int64\n",
      "False    1409766\n",
      "True      183384\n",
      "Name: stats.wardsKilled, dtype: int64\n",
      "False    1589762\n",
      "True        3388\n",
      "Name: stats.firstBloodKill, dtype: int64\n",
      "False    1589762\n",
      "True        3388\n",
      "Name: stats.firstBloodAssist, dtype: int64\n",
      "False    1573922\n",
      "True       19228\n",
      "Name: stats.firstTowerKill, dtype: int64\n",
      "False    1573922\n",
      "True       19228\n",
      "Name: stats.firstTowerAssist, dtype: int64\n",
      "False    1208562\n",
      "True      384588\n",
      "Name: stats.firstInhibitorKill, dtype: int64\n",
      "False    1208562\n",
      "True      384588\n",
      "Name: stats.firstInhibitorAssist, dtype: int64\n",
      "False    1592869\n",
      "True         281\n",
      "Name: stats.perkSubStyle, dtype: int64\n",
      "False    1591566\n",
      "True        1584\n",
      "Name: stats.statPerk0, dtype: int64\n",
      "False    1591566\n",
      "True        1584\n",
      "Name: stats.statPerk1, dtype: int64\n",
      "False    1591566\n",
      "True        1584\n",
      "Name: stats.statPerk2, dtype: int64\n",
      "False    1093532\n",
      "True      499618\n",
      "Name: timeline.creepsPerMinDeltas.10-20, dtype: int64\n",
      "False    1564366\n",
      "True       28784\n",
      "Name: timeline.creepsPerMinDeltas.0-10, dtype: int64\n",
      "False    1093532\n",
      "True      499618\n",
      "Name: timeline.xpPerMinDeltas.10-20, dtype: int64\n",
      "False    1564366\n",
      "True       28784\n",
      "Name: timeline.xpPerMinDeltas.0-10, dtype: int64\n",
      "False    1093532\n",
      "True      499618\n",
      "Name: timeline.goldPerMinDeltas.10-20, dtype: int64\n",
      "False    1564366\n",
      "True       28784\n",
      "Name: timeline.goldPerMinDeltas.0-10, dtype: int64\n",
      "True     864052\n",
      "False    729098\n",
      "Name: timeline.csDiffPerMinDeltas.10-20, dtype: int64\n",
      "False    1199932\n",
      "True      393218\n",
      "Name: timeline.csDiffPerMinDeltas.0-10, dtype: int64\n",
      "True     864052\n",
      "False    729098\n",
      "Name: timeline.xpDiffPerMinDeltas.10-20, dtype: int64\n",
      "False    1199932\n",
      "True      393218\n",
      "Name: timeline.xpDiffPerMinDeltas.0-10, dtype: int64\n",
      "False    1093532\n",
      "True      499618\n",
      "Name: timeline.damageTakenPerMinDeltas.10-20, dtype: int64\n",
      "False    1564366\n",
      "True       28784\n",
      "Name: timeline.damageTakenPerMinDeltas.0-10, dtype: int64\n",
      "True     864052\n",
      "False    729098\n",
      "Name: timeline.damageTakenDiffPerMinDeltas.10-20, dtype: int64\n",
      "False    1199932\n",
      "True      393218\n",
      "Name: timeline.damageTakenDiffPerMinDeltas.0-10, dtype: int64\n",
      "True     1276820\n",
      "False     316330\n",
      "Name: timeline.creepsPerMinDeltas.20-30, dtype: int64\n",
      "True     1276820\n",
      "False     316330\n",
      "Name: timeline.xpPerMinDeltas.20-30, dtype: int64\n",
      "True     1276820\n",
      "False     316330\n",
      "Name: timeline.goldPerMinDeltas.20-30, dtype: int64\n",
      "True     1366124\n",
      "False     227026\n",
      "Name: timeline.csDiffPerMinDeltas.20-30, dtype: int64\n",
      "True     1366124\n",
      "False     227026\n",
      "Name: timeline.xpDiffPerMinDeltas.20-30, dtype: int64\n",
      "True     1276820\n",
      "False     316330\n",
      "Name: timeline.damageTakenPerMinDeltas.20-30, dtype: int64\n",
      "True     1366124\n",
      "False     227026\n",
      "Name: timeline.damageTakenDiffPerMinDeltas.20-30, dtype: int64\n",
      "True     1582408\n",
      "False      10742\n",
      "Name: highestAchievedSeasonTier, dtype: int64\n",
      "True     1494020\n",
      "False      99130\n",
      "Name: timeline.creepsPerMinDeltas.30-end, dtype: int64\n",
      "True     1494020\n",
      "False      99130\n",
      "Name: timeline.xpPerMinDeltas.30-end, dtype: int64\n",
      "True     1494020\n",
      "False      99130\n",
      "Name: timeline.goldPerMinDeltas.30-end, dtype: int64\n",
      "True     1521006\n",
      "False      72144\n",
      "Name: timeline.csDiffPerMinDeltas.30-end, dtype: int64\n",
      "True     1521006\n",
      "False      72144\n",
      "Name: timeline.xpDiffPerMinDeltas.30-end, dtype: int64\n",
      "True     1494020\n",
      "False      99130\n",
      "Name: timeline.damageTakenPerMinDeltas.30-end, dtype: int64\n",
      "True     1521006\n",
      "False      72144\n",
      "Name: timeline.damageTakenDiffPerMinDeltas.30-end, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#look for na in our dataset by column\n",
    "pd.set_option('display.max_columns', None)\n",
    "for col in players_df.columns:\n",
    "    numNa = players_df[col].isnull().value_counts()\n",
    "    try:\n",
    "        if numNa.values[1] > 100:\n",
    "            print(numNa)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in columns \"stats.wardsPlaced\" and \"stats.wardsKilled\" and they have NaN values, therefore we are going to drop rows to get these clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df_gg = players_df.dropna(subset=[\"stats.wardsPlaced\",\"stats.wardsKilled\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create subsets to work with, select columns we want\n",
    "x = players_df_gg[[\"stats.kills\",\"stats.deaths\",\"stats.assists\",\"stats.totalDamageDealt\",\"stats.magicDamageDealt\",\"stats.physicalDamageDealt\",\"stats.trueDamageDealt\",\"stats.totalDamageDealtToChampions\",\"stats.magicDamageDealtToChampions\",\"stats.physicalDamageDealtToChampions\",\"stats.trueDamageDealtToChampions\",\"stats.totalHeal\",\"stats.damageSelfMitigated\",\"stats.damageDealtToObjectives\",\"stats.damageDealtToTurrets\",\"stats.totalDamageTaken\",\"stats.magicalDamageTaken\",\"stats.physicalDamageTaken\",\"stats.trueDamageTaken\",\"stats.goldEarned\",\"stats.goldSpent\",\"stats.turretKills\",\"stats.inhibitorKills\",\"stats.totalMinionsKilled\",\"stats.neutralMinionsKilled\",\"stats.champLevel\",\"stats.wardsPlaced\",\"stats.wardsKilled\"]]\n",
    "y = players_df_gg[[\"championId\",\"spell1Id\",\"spell2Id\",\"timeline.role\",\"timeline.lane\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for na in our dataset by column\n",
    "pd.set_option('display.max_columns', None)\n",
    "for col in x.columns:\n",
    "    numNa = x[col].isnull().value_counts()\n",
    "    try:\n",
    "        if numNa.values[1] > 100:\n",
    "            print(numNa)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for na in our dataset by column\n",
    "pd.set_option('display.max_columns', None)\n",
    "for col in y.columns:\n",
    "    numNa = y[col].isnull().value_counts()\n",
    "    try:\n",
    "        if numNa.values[1] > 100:\n",
    "            print(numNa)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't got NaN values in the biggest subset of the dataset that we will try, we are good. All test will be reducing the amount of columns already selected in x and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different models\n",
    "In order to make testing in a more controlled manner we created classes and a function, (if you want to see the working process of creating this classes you can find the notebooks in the appendix folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN , PCA+KNN  and CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "class knn_predictor():\n",
    "    def __init__(self,x,y,num_neighb = 1):\n",
    "        self.values_in = x.columns.values\n",
    "        self.values_out = y.columns.values\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(x, y, test_size=0.25, random_state=42) #Keep 25% of the data as the test set\n",
    "        self.n_neighbours = num_neighb # Number of neigbours we will use for the classification by default\n",
    "        self.clf = neighbors.KNeighborsClassifier(self.n_neighbours, weights='distance', algorithm = 'kd_tree')\n",
    "        self.clf.fit(self.X_train, np.ravel(self.y_train))\n",
    "        self.clf.get_params()\n",
    "\n",
    "    def predict(self,input):\n",
    "        print(self.clf.predict([input]))\n",
    "    \n",
    "    def accuracy(self):\n",
    "        #print(\"Train Accuracy : \" + str(self.clf.score(self.X_train, self.y_train)))\n",
    "        print(\"Test Accuracy : \" + str(self.clf.score(self.X_test, self.y_test)))\n",
    "        None\n",
    "\n",
    "\n",
    "class pca_and_knn():\n",
    "    def __init__(self,n_components,x,y,neighbors=1):\n",
    "        #first we standarize all our data to prepare it for PCA\n",
    "        self.scaler = StandardScaler()\n",
    "        self.n_components = n_components\n",
    "        self.Xcentred = self.scaler.fit_transform(x)\n",
    "        self.y = y\n",
    "\n",
    "        #we want to transform our data create PCA object\n",
    "        self.pca = PCA(self.n_components)\n",
    "\n",
    "        #calculate\n",
    "        self.pca.fit(self.Xcentred)\n",
    "\n",
    "        #new dataset \n",
    "        self.Xnew = self.pca.transform(self.Xcentred) #here it is a np array we want a pd dataframe\n",
    "        self.Xnew = pd.DataFrame(self.Xnew)\n",
    "        self.reduced_full = pd.merge(self.Xnew, self.y, left_index=True, right_index=True)\n",
    "\n",
    "        self.knn_mod = knn_predictor(self.Xnew,self.y.to_frame(),neighbors)\n",
    "    def variance_explained(self):\n",
    "        print(\"\\nThe components we have found, explain the following percentage of variance: \\n\", self.pca.explained_variance_ratio_) # explained_variance_ratio_ stores the percentage of variance each of our components explains\n",
    "    \n",
    "    def predict_knn(self,entry):\n",
    "        #self.entry = self.pca.transform(self.scaler.fit_transform(entry))\n",
    "        self.entry = self.scaler.transform(entry.to_frame().T)\n",
    "        self.entry = self.pca.transform(self.entry)\n",
    "        #we reuse the class we created before\n",
    "        self.knn_mod.predict(self.entry[0])\n",
    "        \n",
    "    def knn_accuracy(self):\n",
    "        self.knn_mod.accuracy()\n",
    "\n",
    "\n",
    "def correlation_most_sim(x,y,input,methd=\"pearson\",topN=1):\n",
    "    similarity = x.corrwith(input, axis = \"columns\", method = methd) # This function calculates everything based on common items (e.g. mean of user is calculated based only on the common items with that other user we correlate with)\n",
    "    similarity.sort_values(ascending = False, inplace = True)\n",
    "    return [y.iloc[similarity[:topN].index],x.iloc[similarity[:topN].index],similarity[:topN],]\n",
    "\n",
    "\n",
    "class kmeans_mod():\n",
    "    def __init__(self,n_clusterss,x):\n",
    "        #normalitzar dades\n",
    "        self.scaler = StandardScaler()\n",
    "        self.Xcentred = self.scaler.fit_transform(x)\n",
    "        \n",
    "        self.kmeans = KMeans(n_clusters=n_clusterss, random_state=0).fit(self.Xcentred)\n",
    "        warnings.filterwarnings(action='ignore', category=UserWarning) #we filter \n",
    "\n",
    "    def labels(self):\n",
    "        return self.kmeans.labels_\n",
    "    \n",
    "    def predict(self,entryes):\n",
    "        self.entry = self.scaler.transform(entryes.to_frame().T)\n",
    "        return self.kmeans.predict(self.entry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a knn classifier to predict the most suitable champion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.7254470239074798\n"
     ]
    }
   ],
   "source": [
    "knn_pred = knn_predictor(x,pd.DataFrame(y[\"championId\"]),1) #one neighbour\n",
    "knn_pred.accuracy() #the class already does does train/test splitting of the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#We can also predict entries\n",
    "knn_pred.predict(x.iloc[33])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we can calculate its accuracy but this is only with one neighbour, lets try up to 5 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbours: 1\n",
      "Test Accuracy : 0.7254470239074798\n",
      "Neighbours: 2\n",
      "Test Accuracy : 0.725444186561193\n",
      "Neighbours: 3\n",
      "Test Accuracy : 0.7284177254697227\n",
      "Neighbours: 4\n",
      "Test Accuracy : 0.7335107620544657\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,5):\n",
    "    knn_pred = knn_predictor(x,pd.DataFrame(y[\"championId\"]),n) #one neighbour\n",
    "    print(\"Neighbours: \"+format(n))\n",
    "    knn_pred.accuracy() #the class already does does train/test splitting of the input dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More neighbours are giving more test accuracy! let's see how far it goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbours: 15\n",
      "Test Accuracy : 0.7556732739003864\n",
      "Neighbours: 16\n",
      "Test Accuracy : 0.7563003274297615\n",
      "Neighbours: 17\n",
      "Test Accuracy : 0.7565500139029968\n",
      "Neighbours: 18\n",
      "Test Accuracy : 0.7565386645178498\n",
      "Neighbours: 19\n",
      "Test Accuracy : 0.756498941669835\n",
      "Neighbours: 20\n",
      "Test Accuracy : 0.7563797731257909\n",
      "Neighbours: 21\n",
      "Test Accuracy : 0.7563372129314895\n",
      "Neighbours: 22\n",
      "Test Accuracy : 0.7564705682069673\n",
      "Neighbours: 23\n",
      "Test Accuracy : 0.7567571401819306\n",
      "Neighbours: 24\n",
      "Test Accuracy : 0.7565188030938423\n",
      "Neighbours: 25\n",
      "Test Accuracy : 0.7566408089841733\n",
      "Neighbours: 26\n",
      "Test Accuracy : 0.7565443392104233\n",
      "Neighbours: 27\n",
      "Test Accuracy : 0.7564336827052395\n",
      "Neighbours: 28\n",
      "Test Accuracy : 0.7564053092423718\n",
      "Neighbours: 29\n",
      "Test Accuracy : 0.7563343755852027\n"
     ]
    }
   ],
   "source": [
    "for n in range(15,30):\n",
    "    knn_pred = knn_predictor(x,pd.DataFrame(y[\"championId\"]),n) #one neighbour\n",
    "    print(\"Neighbours: \"+format(n))\n",
    "    knn_pred.accuracy() #the class already does does train/test splitting of the input dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA+KNN ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the same dataset lets try doing PCA and then classifying using knn again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The components we have found, explain the following percentage of variance: \n",
      " [0.37250628 0.12018041 0.08157546 0.07175328 0.06426078 0.03873198\n",
      " 0.03598934 0.02961064 0.02758447 0.02397564 0.02173817 0.01925794\n",
      " 0.01624248 0.01433543 0.01382627]\n"
     ]
    }
   ],
   "source": [
    "pca_mod = pca_and_knn(15,x,y[\"championId\"]) #we are reducing to 4 components\n",
    "pca_mod.variance_explained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142]\n"
     ]
    }
   ],
   "source": [
    "##see that we can also make predictions\n",
    "pca_mod.predict_knn(x.iloc[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.5672280829186079\n"
     ]
    }
   ],
   "source": [
    "#and we can also calculate the knn accuracy\n",
    "pca_mod.knn_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for the best combination of columns for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create this functions to recursively generate all combinations of columns\n",
    "import numpy as np\n",
    "def all_except(array):\n",
    "    combinations = []\n",
    "    for idx in range(len(array)):\n",
    "        current_combination = np.delete(array,idx)\n",
    "        combinations.append(list(current_combination))\n",
    "        if len(current_combination) > 2:\n",
    "            sub_comb = all_except(current_combination)\n",
    "            for combi in sub_comb:\n",
    "                if not (combi in combinations):\n",
    "                    combinations.append(list(combi))\n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4],\n",
       " [3, 4],\n",
       " [2, 4],\n",
       " [2, 3],\n",
       " [1, 3, 4],\n",
       " [1, 4],\n",
       " [1, 3],\n",
       " [1, 2, 4],\n",
       " [1, 2],\n",
       " [1, 2, 3]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for testing purposes:\n",
    "all_except([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change of input data, we reduce the numer of columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#28 columns is an inmense amount of combinations that is why we are only going to use the combinations of the following selected columns\n",
    "x2 = x[[\"stats.kills\",\"stats.assists\",\"stats.magicDamageDealt\",\"stats.physicalDamageDealt\",\"stats.damageDealtToTurrets\",\"stats.totalDamageTaken\",\"stats.turretKills\",\"stats.totalMinionsKilled\",\"stats.totalHeal\"]]\n",
    "col_comb = all_except(list(x2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/501\n",
      "2/501\n",
      "3/501\n",
      "60/501\n",
      "91/501\n",
      "107/501\n",
      "115/501\n",
      "119/501\n",
      "121/501\n",
      "122/501\n",
      "123/501\n",
      "154/501\n",
      "170/501\n",
      "178/501\n",
      "182/501\n",
      "184/501\n",
      "185/501\n",
      "186/501\n",
      "202/501\n",
      "210/501\n",
      "214/501\n",
      "216/501\n",
      "217/501\n",
      "218/501\n",
      "226/501\n",
      "230/501\n",
      "232/501\n",
      "233/501\n",
      "234/501\n",
      "238/501\n",
      "240/501\n",
      "241/501\n",
      "242/501\n",
      "244/501\n",
      "245/501\n",
      "246/501\n",
      "247/501\n",
      "248/501\n",
      "249/501\n",
      "250/501\n",
      "281/501\n",
      "297/501\n",
      "305/501\n",
      "309/501\n",
      "311/501\n",
      "312/501\n",
      "313/501\n",
      "329/501\n",
      "337/501\n",
      "341/501\n",
      "343/501\n",
      "344/501\n",
      "345/501\n",
      "353/501\n",
      "357/501\n",
      "359/501\n",
      "360/501\n",
      "361/501\n",
      "365/501\n",
      "367/501\n",
      "368/501\n",
      "369/501\n",
      "371/501\n",
      "372/501\n",
      "373/501\n",
      "374/501\n",
      "375/501\n",
      "376/501\n",
      "377/501\n",
      "393/501\n",
      "401/501\n",
      "405/501\n",
      "407/501\n",
      "408/501\n",
      "409/501\n",
      "417/501\n",
      "421/501\n",
      "423/501\n",
      "424/501\n",
      "425/501\n",
      "429/501\n",
      "431/501\n",
      "432/501\n",
      "433/501\n",
      "435/501\n",
      "436/501\n",
      "437/501\n",
      "438/501\n",
      "439/501\n",
      "440/501\n",
      "441/501\n",
      "449/501\n",
      "453/501\n",
      "455/501\n",
      "456/501\n",
      "457/501\n",
      "461/501\n",
      "463/501\n",
      "464/501\n",
      "465/501\n",
      "467/501\n",
      "468/501\n",
      "469/501\n",
      "470/501\n",
      "471/501\n",
      "472/501\n",
      "473/501\n",
      "477/501\n",
      "479/501\n",
      "480/501\n",
      "481/501\n",
      "483/501\n",
      "484/501\n",
      "485/501\n",
      "486/501\n",
      "487/501\n",
      "488/501\n",
      "489/501\n",
      "491/501\n",
      "492/501\n",
      "493/501\n",
      "494/501\n",
      "495/501\n",
      "496/501\n",
      "497/501\n",
      "498/501\n",
      "499/501\n",
      "500/501\n",
      "501/501\n"
     ]
    }
   ],
   "source": [
    "#Now we will do pca with 5 components for each combination\n",
    "results = []\n",
    "cnt = 0\n",
    "lenght = len(col_comb)\n",
    "for cols in col_comb:\n",
    "    cnt +=1\n",
    "    if len(cols) > 5:\n",
    "        print(format(cnt)+\"/\"+format(lenght))\n",
    "        pca_mod = pca_and_knn(4,x2[cols],y[\"championId\"]) #we are reducing to 4 components\n",
    "        results.append([cols,pca_mod.knn_mod.clf.score(pca_mod.knn_mod.X_test, pca_mod.knn_mod.y_test),pca_mod.pca.explained_variance_ratio_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>variance_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[stats.assists, stats.magicDamageDealt, stats....</td>\n",
       "      <td>0.555822</td>\n",
       "      <td>[0.35028980493212897, 0.24558752761669123, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[stats.magicDamageDealt, stats.physicalDamageD...</td>\n",
       "      <td>0.584760</td>\n",
       "      <td>[0.39064344181600347, 0.25899823954028484, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[stats.physicalDamageDealt, stats.damageDealtT...</td>\n",
       "      <td>0.560262</td>\n",
       "      <td>[0.45321768292304876, 0.24983101999913476, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[stats.magicDamageDealt, stats.damageDealtToTu...</td>\n",
       "      <td>0.571524</td>\n",
       "      <td>[0.3909182849380097, 0.28598142131697907, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[stats.magicDamageDealt, stats.physicalDamageD...</td>\n",
       "      <td>0.603399</td>\n",
       "      <td>[0.3771158712436026, 0.28249466414423874, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>[stats.kills, stats.assists, stats.magicDamage...</td>\n",
       "      <td>0.526529</td>\n",
       "      <td>[0.3836344350157578, 0.2396916917465311, 0.144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>[stats.kills, stats.assists, stats.magicDamage...</td>\n",
       "      <td>0.542265</td>\n",
       "      <td>[0.3784915635844839, 0.21724566489516542, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>[stats.kills, stats.assists, stats.magicDamage...</td>\n",
       "      <td>0.532811</td>\n",
       "      <td>[0.3727184219514579, 0.23070123029435444, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>[stats.kills, stats.assists, stats.magicDamage...</td>\n",
       "      <td>0.523556</td>\n",
       "      <td>[0.39481241601880546, 0.21623809417174816, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>[stats.kills, stats.assists, stats.magicDamage...</td>\n",
       "      <td>0.539476</td>\n",
       "      <td>[0.3890458898391072, 0.19369926436889343, 0.12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               columns  precision_test  \\\n",
       "0    [stats.assists, stats.magicDamageDealt, stats....        0.555822   \n",
       "1    [stats.magicDamageDealt, stats.physicalDamageD...        0.584760   \n",
       "2    [stats.physicalDamageDealt, stats.damageDealtT...        0.560262   \n",
       "3    [stats.magicDamageDealt, stats.damageDealtToTu...        0.571524   \n",
       "4    [stats.magicDamageDealt, stats.physicalDamageD...        0.603399   \n",
       "..                                                 ...             ...   \n",
       "124  [stats.kills, stats.assists, stats.magicDamage...        0.526529   \n",
       "125  [stats.kills, stats.assists, stats.magicDamage...        0.542265   \n",
       "126  [stats.kills, stats.assists, stats.magicDamage...        0.532811   \n",
       "127  [stats.kills, stats.assists, stats.magicDamage...        0.523556   \n",
       "128  [stats.kills, stats.assists, stats.magicDamage...        0.539476   \n",
       "\n",
       "                                         variance_prop  \n",
       "0    [0.35028980493212897, 0.24558752761669123, 0.1...  \n",
       "1    [0.39064344181600347, 0.25899823954028484, 0.1...  \n",
       "2    [0.45321768292304876, 0.24983101999913476, 0.1...  \n",
       "3    [0.3909182849380097, 0.28598142131697907, 0.13...  \n",
       "4    [0.3771158712436026, 0.28249466414423874, 0.14...  \n",
       "..                                                 ...  \n",
       "124  [0.3836344350157578, 0.2396916917465311, 0.144...  \n",
       "125  [0.3784915635844839, 0.21724566489516542, 0.14...  \n",
       "126  [0.3727184219514579, 0.23070123029435444, 0.12...  \n",
       "127  [0.39481241601880546, 0.21623809417174816, 0.1...  \n",
       "128  [0.3890458898391072, 0.19369926436889343, 0.12...  \n",
       "\n",
       "[129 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns = ['columns', 'precision_test',\"variance_prop\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>variance_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[stats.magicDamageDealt, stats.physicalDamageD...</td>\n",
       "      <td>0.603399</td>\n",
       "      <td>[0.3771158712436026, 0.28249466414423874, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[stats.kills, stats.magicDamageDealt, stats.ph...</td>\n",
       "      <td>0.601526</td>\n",
       "      <td>[0.41285686851522896, 0.267998486413778, 0.145...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              columns  precision_test  \\\n",
       "4   [stats.magicDamageDealt, stats.physicalDamageD...        0.603399   \n",
       "53  [stats.kills, stats.magicDamageDealt, stats.ph...        0.601526   \n",
       "\n",
       "                                        variance_prop  \n",
       "4   [0.3771158712436026, 0.28249466414423874, 0.14...  \n",
       "53  [0.41285686851522896, 0.267998486413778, 0.145...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#asking for precision over 0.6 is showing only 2 combinations\n",
    "results_df[results_df[\"precision_test\"]>0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORRELATION_MOST_SIMILAR------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>championId</th>\n",
       "      <th>spell1Id</th>\n",
       "      <th>spell2Id</th>\n",
       "      <th>timeline.role</th>\n",
       "      <th>timeline.lane</th>\n",
       "      <th>name</th>\n",
       "      <th>partype</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>DUO_SUPPORT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Lee Sin</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Fighter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     championId  spell1Id  spell2Id timeline.role timeline.lane     name  \\\n",
       "233          64        11         4   DUO_SUPPORT          NONE  Lee Sin   \n",
       "\n",
       "    partype      tag  \n",
       "233  Energy  Fighter  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will take as an input random entry from x\n",
    "input = x.iloc[3333]\n",
    "x_without_input = x.drop(index=3333)\n",
    "correlation_most_sim(x.iloc[:300],y,input,methd=\"pearson\",topN=1)[0] #using only 300 of x for quick testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_precision_corr_rec(x,y,Nevals,y_columns_targeted,method=\"pearson\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42) #Keep 25% of the data as the test set\n",
    "    precision = 0\n",
    "\n",
    "    eval_subset = X_test.iloc[:Nevals]\n",
    "    eval_subset = eval_subset.reset_index()\n",
    "    eval_subset_y = y_test.iloc[:Nevals]\n",
    "    eval_subset_y = eval_subset_y.reset_index()\n",
    "    for idx in range(Nevals):\n",
    "        print(format(idx)+\"/\"+format(Nevals))\n",
    "        entry = eval_subset.iloc[idx].drop(\"index\")\n",
    "        entry_y = eval_subset_y.iloc[idx]\n",
    "        try:\n",
    "            recommendation = correlation_most_sim(X_train,y_train,entry,methd=method,topN=1)[0]\n",
    "            if(np.ravel(recommendation[y_columns_targeted])[0] == entry_y[\"championId\"]):\n",
    "                precision += 1\n",
    "        except:\n",
    "            None\n",
    "            \n",
    "    return precision/Nevals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORRELATION_RECOMMENDER------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think of the situation where given certain values like:\n",
    "[\"stats.kills\",\"stats.assists\",\"stats.magicDamageDealt\",\"stats.physicalDamageDealt\",\"stats.damageDealtToTurrets\",\"stats.totalDamageTaken\",\"stats.turretKills\",\"stats.totalMinionsKilled\",\"stats.totalHeal\"] we want to predict one of them.\n",
    "For example, how many turrets is going to kill someone with the other characteristics?\n",
    "My intuition says that probably someone with a lot of physical damage will have more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse the correlation_recommend function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py:1482\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1480'>1481</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1481'>1482</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_take_with_is_copy(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1482'>1483</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1483'>1484</a>\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py:3716\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3708'>3709</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3709'>3710</a>\u001b[0m \u001b[39mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3710'>3711</a>\u001b[0m \u001b[39mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3713'>3714</a>\u001b[0m \u001b[39mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3714'>3715</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3715'>3716</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3716'>3717</a>\u001b[0m \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py:3703\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3700'>3701</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m-> <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3702'>3703</a>\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3703'>3704</a>\u001b[0m     indices, axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis), verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3704'>3705</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/generic.py?line=3705'>3706</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/internals/managers.py:897\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/internals/managers.py?line=895'>896</a>\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[axis]\n\u001b[0;32m--> <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/internals/managers.py?line=896'>897</a>\u001b[0m indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39;49mverify)\n\u001b[1;32m    <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/internals/managers.py?line=898'>899</a>\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m~/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexers/utils.py:292\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexers/utils.py?line=290'>291</a>\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m--> <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexers/utils.py?line=291'>292</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mindices are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexers/utils.py?line=292'>293</a>\u001b[0m \u001b[39mreturn\u001b[39;00m indices\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/Models.ipynb Cell 41'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/Models.ipynb#ch0000086?line=2'>3</a>\u001b[0m x_without_input \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mdrop(index\u001b[39m=\u001b[39m\u001b[39m3333\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/Models.ipynb#ch0000086?line=3'>4</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mstats.turretKills\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/Models.ipynb#ch0000086?line=4'>5</a>\u001b[0m output_most_sim \u001b[39m=\u001b[39m correlation_most_sim(x\u001b[39m.\u001b[39;49miloc[:\u001b[39m300\u001b[39;49m],y,\u001b[39minput\u001b[39;49m,methd\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpearson\u001b[39;49m\u001b[39m\"\u001b[39;49m,topN\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/Models.ipynb Cell 12'\u001b[0m in \u001b[0;36mcorrelation_most_sim\u001b[0;34m(x, y, input, methd, topN)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/Models.ipynb#ch0000011?line=63'>64</a>\u001b[0m similarity \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mcorrwith(\u001b[39minput\u001b[39m, axis \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m, method \u001b[39m=\u001b[39m methd) \u001b[39m# This function calculates everything based on common items (e.g. mean of user is calculated based only on the common items with that other user we correlate with)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/Models.ipynb#ch0000011?line=64'>65</a>\u001b[0m similarity\u001b[39m.\u001b[39msort_values(ascending \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/Models.ipynb#ch0000011?line=65'>66</a>\u001b[0m \u001b[39mreturn\u001b[39;00m [y\u001b[39m.\u001b[39miloc[similarity[:topN]\u001b[39m.\u001b[39mindex],x\u001b[39m.\u001b[39;49miloc[similarity[:topN]\u001b[39m.\u001b[39;49mindex],similarity[:topN],]\n",
      "File \u001b[0;32m~/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=963'>964</a>\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=965'>966</a>\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m--> <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=966'>967</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py:1511\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1508'>1509</a>\u001b[0m \u001b[39m# a list of integers\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1509'>1510</a>\u001b[0m \u001b[39melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1510'>1511</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_list_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1512'>1513</a>\u001b[0m \u001b[39m# a single integer\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1513'>1514</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1514'>1515</a>\u001b[0m     key \u001b[39m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py:1485\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1481'>1482</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_take_with_is_copy(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1482'>1483</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1483'>1484</a>\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/pepe/Documents/UNI/data_engineering/ProjecteDades/projecte_dades_env/lib/python3.9/site-packages/pandas/core/indexing.py?line=1484'>1485</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpositional indexers are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "#grap top 100, 100 arbitrarely, could be larger and compute the expected value\n",
    "input = x.iloc[3333]\n",
    "x_without_input = x.drop(index=3333)\n",
    "input = input.drop(\"stats.turretKills\")\n",
    "output_most_sim = correlation_most_sim(x.iloc[:300],y,input,methd=\"pearson\",topN=100)\n",
    "#similar_boyszz = output_most_sim[0] #using only 300 of x for quick testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>championId</th>\n",
       "      <th>spell1Id</th>\n",
       "      <th>spell2Id</th>\n",
       "      <th>timeline.role</th>\n",
       "      <th>timeline.lane</th>\n",
       "      <th>name</th>\n",
       "      <th>partype</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>DUO_SUPPORT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Lee Sin</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Fighter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>89</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>DUO_SUPPORT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Leona</td>\n",
       "      <td>Mana</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NONE</td>\n",
       "      <td>JUNGLE</td>\n",
       "      <td>Nocturne</td>\n",
       "      <td>Mana</td>\n",
       "      <td>Assassin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>246</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NONE</td>\n",
       "      <td>JUNGLE</td>\n",
       "      <td>Qiyana</td>\n",
       "      <td>Mana</td>\n",
       "      <td>Assassin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>163</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NONE</td>\n",
       "      <td>JUNGLE</td>\n",
       "      <td>Taliyah</td>\n",
       "      <td>Mana</td>\n",
       "      <td>Mage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     championId  spell1Id  spell2Id timeline.role timeline.lane      name  \\\n",
       "233          64        11         4   DUO_SUPPORT          NONE   Lee Sin   \n",
       "188          89        14         4   DUO_SUPPORT          NONE     Leona   \n",
       "85           56         4        12          NONE        JUNGLE  Nocturne   \n",
       "169         246         4        11          NONE        JUNGLE    Qiyana   \n",
       "195         163         4        11          NONE        JUNGLE   Taliyah   \n",
       "\n",
       "    partype       tag  \n",
       "233  Energy   Fighter  \n",
       "188    Mana      Tank  \n",
       "85     Mana  Assassin  \n",
       "169    Mana  Assassin  \n",
       "195    Mana      Mage  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_boyszz.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use this formula for predicting, but in our case it doesn't make sense to use the distance of the desired value rb,i with the mean of all b. This is due to that each column is its own metric with its own range of values. Not apples to apples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ pred(a, i) = \\hat{r_a} + \\frac{\\sum_{b \\in N} sim(a, b) (r_{b,i} - \\hat{r_b})}{\\sum_{b \\in N} sim(a,b)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is why we will do the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ pred(a, i) = \\frac{\\sum_{b \\in N} sim(a, b) (r_{b,i})}{\\sum_{b \\in N} sim(a,b)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/Models.ipynb Cell 47'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pepe/Documents/UNI/data_engineering/ProjecteDades/Models.ipynb#ch0000095?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(output_most_sim[\u001b[39m2\u001b[39;49m][\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(output_most_sim[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom = den = 0\n",
    "for i in range(100):\n",
    "    nom = output_most_sim[1][0] * similar_boyszz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMEANS--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try and look for groups using kmeans, if we find that it is classifying some label in the y dataset we can use it directly as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing purposes, lets try\n",
    "kmeanssz = kmeans_mod(6,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it is classifying as type 3\n",
    "kmeanssz.predict(x.iloc[34994])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if it can classify something as we have labeled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_precision_testing(x,y,labels,Nevals=0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42) #Keep 25% of the data as the test set\n",
    "    precision = 0\n",
    "    \n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    y_test = y_test.reset_index()[:Nevals]\n",
    "    \n",
    "    nfeatures = len(y[labels].value_counts().index)\n",
    "    kmean_modelu = kmeans_mod(nfeatures,X_train)\n",
    "    \n",
    "    if Nevals == 0:\n",
    "        Nevals = len(X_test)\n",
    "\n",
    "    predictions = []\n",
    "    for idx in range(len(y_test)):  \n",
    "        #print(format(idx)+\"/\"+format(Nevals)) \n",
    "        try:\n",
    "            predictions.append(int(kmean_modelu.predict(X_test.iloc[idx])))\n",
    "        except:\n",
    "            None\n",
    "    y_test[\"classified_as\"] = predictions\n",
    "    \n",
    "    results_cols = []\n",
    "    for indexito in y[labels].value_counts().index:\n",
    "        results_cols.append(indexito[0])\n",
    "\n",
    "    results = pd.DataFrame(columns=results_cols)\n",
    "\n",
    "    valcounts = []\n",
    "    for label_value in y[labels].value_counts().index:\n",
    "        value_counts = y_test[y_test[labels[0]]==label_value[0]][\"classified_as\"].value_counts()\n",
    "        kmean_groups = value_counts.index.values\n",
    "        \n",
    "        for grp_val in kmean_groups:\n",
    "            results.at[grp_val,label_value[0]] = value_counts[grp_val]\n",
    "\n",
    "    results = results.sort_index()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a test let's start with \"timeline.lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NONE</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>MIDDLE</th>\n",
       "      <th>JUNGLE</th>\n",
       "      <th>TOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NONE BOTTOM MIDDLE JUNGLE  TOP\n",
       "0  NaN      6      1    NaN  NaN\n",
       "1    2      3      3      1    1\n",
       "2  NaN    NaN      1      3    2\n",
       "3  NaN      4      1      2    2\n",
       "4   15      2      1    NaN  NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_precision_testing(x,y,[\"timeline.lane\"],50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that group 2 is related to \"lane\" marked as NONE and BOTTOM, but those two seem to be equally marked as group 3. \"lane\" is not how this kmeans is grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a bunch of collumns and more iterations of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeline.role\n",
      "  DUO_SUPPORT SOLO NONE DUO_CARRY DUO\n",
      "0          88   47   21        23  26\n",
      "1          71   58   37        18  17\n",
      "2          74   52   28        27  22\n",
      "3          79   49   29        27  15\n",
      "4          67   44   29        31  21\n",
      "------\n",
      "DUO_SUPPORT\n",
      "------\n",
      "max: 88\n",
      "median: 74.0\n",
      "mean: 75.8\n",
      "std: 8.105553651663778\n",
      "min: 67\n",
      "\n",
      "------\n",
      "SOLO\n",
      "------\n",
      "max: 58\n",
      "median: 49.0\n",
      "mean: 50.0\n",
      "std: 5.338539126015656\n",
      "min: 44\n",
      "\n",
      "------\n",
      "NONE\n",
      "------\n",
      "max: 37\n",
      "median: 29.0\n",
      "mean: 28.8\n",
      "std: 5.674504383644443\n",
      "min: 21\n",
      "\n",
      "------\n",
      "DUO_CARRY\n",
      "------\n",
      "max: 31\n",
      "median: 27.0\n",
      "mean: 25.2\n",
      "std: 4.919349550499537\n",
      "min: 18\n",
      "\n",
      "------\n",
      "DUO\n",
      "------\n",
      "max: 26\n",
      "median: 21.0\n",
      "mean: 20.2\n",
      "std: 4.324349662087931\n",
      "min: 15\n",
      "\n",
      "\n",
      "timeline.lane\n",
      "  NONE BOTTOM MIDDLE JUNGLE TOP\n",
      "0   63     60     34     21  27\n",
      "1   56     40     39     37  29\n",
      "2   63     52     20     28  40\n",
      "3   57     52     33     29  28\n",
      "4   45     62     31     29  25\n",
      "------\n",
      "NONE\n",
      "------\n",
      "max: 63\n",
      "median: 57.0\n",
      "mean: 56.8\n",
      "std: 7.362064927722384\n",
      "min: 45\n",
      "\n",
      "------\n",
      "BOTTOM\n",
      "------\n",
      "max: 62\n",
      "median: 52.0\n",
      "mean: 53.2\n",
      "std: 8.67179335547152\n",
      "min: 40\n",
      "\n",
      "------\n",
      "MIDDLE\n",
      "------\n",
      "max: 39\n",
      "median: 33.0\n",
      "mean: 31.4\n",
      "std: 7.021395872616783\n",
      "min: 20\n",
      "\n",
      "------\n",
      "JUNGLE\n",
      "------\n",
      "max: 37\n",
      "median: 29.0\n",
      "mean: 28.8\n",
      "std: 5.674504383644443\n",
      "min: 21\n",
      "\n",
      "------\n",
      "TOP\n",
      "------\n",
      "max: 40\n",
      "median: 28.0\n",
      "mean: 29.8\n",
      "std: 5.890670590009257\n",
      "min: 25\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#haven't used championId or spells because it takes too much time to compute\n",
    "columns = [\"timeline.role\",\"timeline.lane\"]\n",
    "for colu in columns:\n",
    "    print(colu)\n",
    "    df = kmeans_precision_testing(x,y,[colu],1000)\n",
    "    print(df)\n",
    "    for col in df.columns:\n",
    "        print(\"------\")\n",
    "        print(str(col))\n",
    "        print(\"------\")\n",
    "        print(\"max: \"+format(df[col].max()))\n",
    "        print(\"median: \"+format(df[col].median()))\n",
    "        print(\"mean: \"+format(df[col].mean()))\n",
    "        print(\"std: \"+format(df[col].std()))\n",
    "        print(\"min: \"+format(df[col].min()))\n",
    "        print(\"\")\n",
    "    \n",
    "    print(\"\") #as en enter, for aesthetics ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try with other data that we can get about our champions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nc/l6y7znsd68z5g8ldgmy_rwyr0000gn/T/ipykernel_10641/1117781004.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y.loc[indexes,[\"name\"]] = champ_info_df.iloc[idx][\"name\"]\n",
      "/var/folders/nc/l6y7znsd68z5g8ldgmy_rwyr0000gn/T/ipykernel_10641/1117781004.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y.loc[indexes,[\"partype\"]] = champ_info_df.iloc[idx][\"partype\"]\n",
      "/var/folders/nc/l6y7znsd68z5g8ldgmy_rwyr0000gn/T/ipykernel_10641/1117781004.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y.loc[indexes,[\"tag\"]] = champ_info_df.iloc[idx][\"tags\"][0] #we get only the first tag\n"
     ]
    }
   ],
   "source": [
    "#We add a new column to y with the type of champion for each entry\n",
    "import json \n",
    "df = pd.read_json('https://ddragon.leagueoflegends.com/cdn/12.8.1/data/en_US/champion.json')\n",
    "\n",
    "#this is not working\n",
    "#pd.DataFrame.from_dict(df.iloc[0][\"data\"])\n",
    "\n",
    "#i will do it manually\n",
    "champ_info_df = pd.DataFrame(columns = df[\"data\"].iloc[0].keys())\n",
    "for idx in range(len(df)):\n",
    "    aux = []\n",
    "    for col in champ_info_df.columns:\n",
    "        aux.append(df.iloc[idx][\"data\"][col])\n",
    "        #print(df.iloc[idx][\"data\"][col])\n",
    "    champ_info_df.loc[idx] =  aux\n",
    "\n",
    "#for each entry in y we will add the champ name and the type\n",
    "for idx in range(len(champ_info_df)):\n",
    "    indexes = y[y[\"championId\"] == int(champ_info_df.iloc[idx][\"key\"])].index #positions of the dataframe where the selected champid of champ_info_df lies\n",
    "    y.loc[indexes,[\"name\"]] = champ_info_df.iloc[idx][\"name\"]\n",
    "    y.loc[indexes,[\"partype\"]] = champ_info_df.iloc[idx][\"partype\"]\n",
    "    y.loc[indexes,[\"tag\"]] = champ_info_df.iloc[idx][\"tags\"][0] #we get only the first tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>championId</th>\n",
       "      <th>spell1Id</th>\n",
       "      <th>spell2Id</th>\n",
       "      <th>timeline.role</th>\n",
       "      <th>timeline.lane</th>\n",
       "      <th>name</th>\n",
       "      <th>partype</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>SOLO</td>\n",
       "      <td>TOP</td>\n",
       "      <td>Irelia</td>\n",
       "      <td>Mana</td>\n",
       "      <td>Fighter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>SOLO</td>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>Rumble</td>\n",
       "      <td>Heat</td>\n",
       "      <td>Fighter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>350</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>DUO_SUPPORT</td>\n",
       "      <td>BOTTOM</td>\n",
       "      <td>Yuumi</td>\n",
       "      <td>Mana</td>\n",
       "      <td>Support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>DUO_CARRY</td>\n",
       "      <td>BOTTOM</td>\n",
       "      <td>Ezreal</td>\n",
       "      <td>Mana</td>\n",
       "      <td>Marksman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NONE</td>\n",
       "      <td>JUNGLE</td>\n",
       "      <td>Sejuani</td>\n",
       "      <td>Mana</td>\n",
       "      <td>Tank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   championId  spell1Id  spell2Id timeline.role timeline.lane     name  \\\n",
       "0          39        12         4          SOLO           TOP   Irelia   \n",
       "1          68        12         4          SOLO        MIDDLE   Rumble   \n",
       "2         350         7        14   DUO_SUPPORT        BOTTOM    Yuumi   \n",
       "3          81        12         4     DUO_CARRY        BOTTOM   Ezreal   \n",
       "4         113         4        11          NONE        JUNGLE  Sejuani   \n",
       "\n",
       "  partype       tag  \n",
       "0    Mana   Fighter  \n",
       "1    Heat   Fighter  \n",
       "2    Mana   Support  \n",
       "3    Mana  Marksman  \n",
       "4    Mana      Tank  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partype\n",
      "   Mana Energy None Grit Fury Rage Blood Well Flow Shield Heat Crimson Rush  \\\n",
      "0   112    NaN  NaN    4  NaN  NaN        NaN  NaN    NaN    1          NaN   \n",
      "1   145      9    3  NaN    6    3        NaN    1      2    2          NaN   \n",
      "2    38      1  NaN  NaN    1    1        NaN    2    NaN  NaN          NaN   \n",
      "3    53    NaN    7    3    3  NaN        NaN    4    NaN  NaN          NaN   \n",
      "4    50     15    2    2  NaN   10        NaN  NaN    NaN  NaN          NaN   \n",
      "5    43     12    2    1    1    2        NaN  NaN    NaN  NaN          NaN   \n",
      "6    23    NaN    1  NaN  NaN  NaN        NaN  NaN      1    1            2   \n",
      "7   147      5    2    3    4    1          6    6      2    3            4   \n",
      "8    82      1    1    5    7  NaN          6    4    NaN  NaN          NaN   \n",
      "9    60      6    4  NaN  NaN  NaN        NaN  NaN      2   10            3   \n",
      "10   11      1    4  NaN    4  NaN          2  NaN    NaN  NaN          NaN   \n",
      "11   16    NaN    3    8  NaN  NaN        NaN  NaN    NaN  NaN          NaN   \n",
      "12    4    NaN  NaN  NaN  NaN  NaN        NaN  NaN    NaN  NaN          NaN   \n",
      "\n",
      "   Courage Ferocity  \n",
      "0      NaN      NaN  \n",
      "1      NaN      NaN  \n",
      "2        1        1  \n",
      "3      NaN      NaN  \n",
      "4      NaN      NaN  \n",
      "5      NaN      NaN  \n",
      "6      NaN      NaN  \n",
      "7      NaN      NaN  \n",
      "8      NaN        2  \n",
      "9      NaN      NaN  \n",
      "10     NaN      NaN  \n",
      "11     NaN      NaN  \n",
      "12     NaN      NaN  \n",
      "\n",
      "tag\n",
      "  Fighter Marksman Mage Support Assassin Tank\n",
      "0      67       52  NaN     NaN        8    4\n",
      "1      65       62   55      49       21   43\n",
      "2       8        2   40     NaN       11   10\n",
      "3      95       84   37       9       35   20\n",
      "4      60        3   15       4       17    8\n",
      "5       7        9   13      58        1   28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#haven't used championId or spells because it takes too much time to compute\n",
    "columns = [\"partype\",\"tag\"]\n",
    "for colu in columns:\n",
    "    print(colu)\n",
    "    df = kmeans_precision_testing(x,y,[colu],1000)\n",
    "    print(df)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: we would hope to see some big values on only one column, big std but it is not the case. We haven't found any relation of the kmeans generated clusters and any class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------\n",
    "# OBJECTIVE: Predict ChampionID\n",
    "# ----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Lets see what model is the best for this pourpose: knn neighbours, or pca and then knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To start we will make sure we are using the same input data\n",
    "x2 = x[[\"stats.kills\",\"stats.assists\",\"stats.magicDamageDealt\",\"stats.physicalDamageDealt\",\"stats.damageDealtToTurrets\",\"stats.totalDamageTaken\",\"stats.turretKills\",\"stats.totalMinionsKilled\",\"stats.totalHeal\"]]\n",
    "y2 = y[\"championId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.661186805204828\n"
     ]
    }
   ],
   "source": [
    "knn_pred = knn_predictor(x2,pd.DataFrame(y[\"championId\"]),6) #as we saw it had more accuracy\n",
    "knn_pred.accuracy() #the class already does does train/test splitting of the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.5455791307505916\n"
     ]
    }
   ],
   "source": [
    "pca_mod = pca_and_knn(4,x2,y[\"championId\"]) #we are reducing to 4 components\n",
    "pca_mod.knn_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that knn has better precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare it to using correlation of entries we have to reduce the dataset size as this is computationally intensive, therefore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = x2[:300000]\n",
    "y3 = pd.DataFrame(y2[:300000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.41329333333333335\n"
     ]
    }
   ],
   "source": [
    "knn_pred = knn_predictor(x3,pd.DataFrame(y3[\"championId\"]),6) #as we saw it had more accuracy\n",
    "knn_pred.accuracy() #the class already does does train/test splitting of the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.15861333333333333\n"
     ]
    }
   ],
   "source": [
    "pca_mod = pca_and_knn(4,x3,y3[\"championId\"]) #we are reducing to 4 components\n",
    "pca_mod.knn_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50\n",
      "1/50\n",
      "2/50\n",
      "3/50\n",
      "4/50\n",
      "5/50\n",
      "6/50\n",
      "7/50\n",
      "8/50\n",
      "9/50\n",
      "10/50\n",
      "11/50\n",
      "12/50\n",
      "13/50\n",
      "14/50\n",
      "15/50\n",
      "16/50\n",
      "17/50\n",
      "18/50\n",
      "19/50\n",
      "20/50\n",
      "21/50\n",
      "22/50\n",
      "23/50\n",
      "24/50\n",
      "25/50\n",
      "26/50\n",
      "27/50\n",
      "28/50\n",
      "29/50\n",
      "30/50\n",
      "31/50\n",
      "32/50\n",
      "33/50\n",
      "34/50\n",
      "35/50\n",
      "36/50\n",
      "37/50\n",
      "38/50\n",
      "39/50\n",
      "40/50\n",
      "41/50\n",
      "42/50\n",
      "43/50\n",
      "44/50\n",
      "45/50\n",
      "46/50\n",
      "47/50\n",
      "48/50\n",
      "49/50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_precision_corr_rec(x3,y3,50,[\"championId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------\n",
    "# OBJECTIVE: Predict spells\n",
    "# ----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPELL1--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To start we will make sure we are using the same input data\n",
    "x4 = x[[\"stats.kills\",\"stats.assists\",\"stats.magicDamageDealt\",\"stats.physicalDamageDealt\",\"stats.damageDealtToTurrets\",\"stats.totalDamageTaken\",\"stats.turretKills\",\"stats.totalMinionsKilled\",\"stats.totalHeal\"]]\n",
    "y4 = y[\"spell1Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.676020451592035\n"
     ]
    }
   ],
   "source": [
    "knn_pred = knn_predictor(x4,pd.DataFrame(y[\"spell1Id\"]),6) #as we saw it had more accuracy\n",
    "knn_pred.accuracy() #the class already does does train/test splitting of the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.641189188575709\n"
     ]
    }
   ],
   "source": [
    "pca_mod = pca_and_knn(4,x4,y[\"spell1Id\"]) #we are reducing to 4 components\n",
    "pca_mod.knn_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll use a smaller dataset for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/100\n",
      "1/100\n",
      "2/100\n",
      "3/100\n",
      "4/100\n",
      "5/100\n",
      "6/100\n",
      "7/100\n",
      "8/100\n",
      "9/100\n",
      "10/100\n",
      "11/100\n",
      "12/100\n",
      "13/100\n",
      "14/100\n",
      "15/100\n",
      "16/100\n",
      "17/100\n",
      "18/100\n",
      "19/100\n",
      "20/100\n",
      "21/100\n",
      "22/100\n",
      "23/100\n",
      "24/100\n",
      "25/100\n",
      "26/100\n",
      "27/100\n",
      "28/100\n",
      "29/100\n",
      "30/100\n",
      "31/100\n",
      "32/100\n",
      "33/100\n",
      "34/100\n",
      "35/100\n",
      "36/100\n",
      "37/100\n",
      "38/100\n",
      "39/100\n",
      "40/100\n",
      "41/100\n",
      "42/100\n",
      "43/100\n",
      "44/100\n",
      "45/100\n",
      "46/100\n",
      "47/100\n",
      "48/100\n",
      "49/100\n",
      "50/100\n",
      "51/100\n",
      "52/100\n",
      "53/100\n",
      "54/100\n",
      "55/100\n",
      "56/100\n",
      "57/100\n",
      "58/100\n",
      "59/100\n",
      "60/100\n",
      "61/100\n",
      "62/100\n",
      "63/100\n",
      "64/100\n",
      "65/100\n",
      "66/100\n",
      "67/100\n",
      "68/100\n",
      "69/100\n",
      "70/100\n",
      "71/100\n",
      "72/100\n",
      "73/100\n",
      "74/100\n",
      "75/100\n",
      "76/100\n",
      "77/100\n",
      "78/100\n",
      "79/100\n",
      "80/100\n",
      "81/100\n",
      "82/100\n",
      "83/100\n",
      "84/100\n",
      "85/100\n",
      "86/100\n",
      "87/100\n",
      "88/100\n",
      "89/100\n",
      "90/100\n",
      "91/100\n",
      "92/100\n",
      "93/100\n",
      "94/100\n",
      "95/100\n",
      "96/100\n",
      "97/100\n",
      "98/100\n",
      "99/100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_precision_corr_rec(x4[:200000],y4[:200000],100,[\"spell1Id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPELL2--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To start we will make sure we are using the same input data\n",
    "x5 = x[[\"stats.kills\",\"stats.assists\",\"stats.magicDamageDealt\",\"stats.physicalDamageDealt\",\"stats.damageDealtToTurrets\",\"stats.totalDamageTaken\",\"stats.turretKills\",\"stats.totalMinionsKilled\",\"stats.totalHeal\"]]\n",
    "y5 = y[\"spell2Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.7887765930280727\n"
     ]
    }
   ],
   "source": [
    "knn_pred = knn_predictor(x5,pd.DataFrame(y[\"spell2Id\"]),6) #as we saw it had more accuracy\n",
    "knn_pred.accuracy() #the class already does does train/test splitting of the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.641189188575709\n"
     ]
    }
   ],
   "source": [
    "pca_mod = pca_and_knn(4,x5,y[\"spell1Id\"]) #we are reducing to 4 components\n",
    "pca_mod.knn_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll use a smaller dataset for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/100\n",
      "1/100\n",
      "2/100\n",
      "3/100\n",
      "4/100\n",
      "5/100\n",
      "6/100\n",
      "7/100\n",
      "8/100\n",
      "9/100\n",
      "10/100\n",
      "11/100\n",
      "12/100\n",
      "13/100\n",
      "14/100\n",
      "15/100\n",
      "16/100\n",
      "17/100\n",
      "18/100\n",
      "19/100\n",
      "20/100\n",
      "21/100\n",
      "22/100\n",
      "23/100\n",
      "24/100\n",
      "25/100\n",
      "26/100\n",
      "27/100\n",
      "28/100\n",
      "29/100\n",
      "30/100\n",
      "31/100\n",
      "32/100\n",
      "33/100\n",
      "34/100\n",
      "35/100\n",
      "36/100\n",
      "37/100\n",
      "38/100\n",
      "39/100\n",
      "40/100\n",
      "41/100\n",
      "42/100\n",
      "43/100\n",
      "44/100\n",
      "45/100\n",
      "46/100\n",
      "47/100\n",
      "48/100\n",
      "49/100\n",
      "50/100\n",
      "51/100\n",
      "52/100\n",
      "53/100\n",
      "54/100\n",
      "55/100\n",
      "56/100\n",
      "57/100\n",
      "58/100\n",
      "59/100\n",
      "60/100\n",
      "61/100\n",
      "62/100\n",
      "63/100\n",
      "64/100\n",
      "65/100\n",
      "66/100\n",
      "67/100\n",
      "68/100\n",
      "69/100\n",
      "70/100\n",
      "71/100\n",
      "72/100\n",
      "73/100\n",
      "74/100\n",
      "75/100\n",
      "76/100\n",
      "77/100\n",
      "78/100\n",
      "79/100\n",
      "80/100\n",
      "81/100\n",
      "82/100\n",
      "83/100\n",
      "84/100\n",
      "85/100\n",
      "86/100\n",
      "87/100\n",
      "88/100\n",
      "89/100\n",
      "90/100\n",
      "91/100\n",
      "92/100\n",
      "93/100\n",
      "94/100\n",
      "95/100\n",
      "96/100\n",
      "97/100\n",
      "98/100\n",
      "99/100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_precision_corr_rec(x5[:200000],y[:200000],100,[\"spell2Id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------\n",
    "# OBJECTIVE: Just for fun, predict other classifications and see precision\n",
    "# ----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make a for loop beacuse we don't want this notebook to be any longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "timeline.role\n",
      "---------\n",
      "KNN\n",
      "Test Accuracy : 0.8352267890887011\n",
      "\n",
      "PCA+KNN\n",
      "Test Accuracy : 0.7776627076228145\n",
      "\n",
      "CORRELATION (on smaller dataset size=5000, test=100)\n",
      "0/100\n",
      "1/100\n",
      "2/100\n",
      "3/100\n",
      "4/100\n",
      "5/100\n",
      "6/100\n",
      "7/100\n",
      "8/100\n",
      "9/100\n",
      "10/100\n",
      "11/100\n",
      "12/100\n",
      "13/100\n",
      "14/100\n",
      "15/100\n",
      "16/100\n",
      "17/100\n",
      "18/100\n",
      "19/100\n",
      "20/100\n",
      "21/100\n",
      "22/100\n",
      "23/100\n",
      "24/100\n",
      "25/100\n",
      "26/100\n",
      "27/100\n",
      "28/100\n",
      "29/100\n",
      "30/100\n",
      "31/100\n",
      "32/100\n",
      "33/100\n",
      "34/100\n",
      "35/100\n",
      "36/100\n",
      "37/100\n",
      "38/100\n",
      "39/100\n",
      "40/100\n",
      "41/100\n",
      "42/100\n",
      "43/100\n",
      "44/100\n",
      "45/100\n",
      "46/100\n",
      "47/100\n",
      "48/100\n",
      "49/100\n",
      "50/100\n",
      "51/100\n",
      "52/100\n",
      "53/100\n",
      "54/100\n",
      "55/100\n",
      "56/100\n",
      "57/100\n",
      "58/100\n",
      "59/100\n",
      "60/100\n",
      "61/100\n",
      "62/100\n",
      "63/100\n",
      "64/100\n",
      "65/100\n",
      "66/100\n",
      "67/100\n",
      "68/100\n",
      "69/100\n",
      "70/100\n",
      "71/100\n",
      "72/100\n",
      "73/100\n",
      "74/100\n",
      "75/100\n",
      "76/100\n",
      "77/100\n",
      "78/100\n",
      "79/100\n",
      "80/100\n",
      "81/100\n",
      "82/100\n",
      "83/100\n",
      "84/100\n",
      "85/100\n",
      "86/100\n",
      "87/100\n",
      "88/100\n",
      "89/100\n",
      "90/100\n",
      "91/100\n",
      "92/100\n",
      "93/100\n",
      "94/100\n",
      "95/100\n",
      "96/100\n",
      "97/100\n",
      "98/100\n",
      "99/100\n",
      "Test Accuracy : 0.0\n",
      "\n",
      "---------\n",
      "timeline.lane\n",
      "---------\n",
      "KNN\n",
      "Test Accuracy : 0.8252166313889945\n",
      "\n",
      "PCA+KNN\n",
      "Test Accuracy : 0.7604258289307176\n",
      "\n",
      "CORRELATION (on smaller dataset size=5000, test=100)\n",
      "0/100\n",
      "1/100\n",
      "2/100\n",
      "3/100\n",
      "4/100\n",
      "5/100\n",
      "6/100\n",
      "7/100\n",
      "8/100\n",
      "9/100\n",
      "10/100\n",
      "11/100\n",
      "12/100\n",
      "13/100\n",
      "14/100\n",
      "15/100\n",
      "16/100\n",
      "17/100\n",
      "18/100\n",
      "19/100\n",
      "20/100\n",
      "21/100\n",
      "22/100\n",
      "23/100\n",
      "24/100\n",
      "25/100\n",
      "26/100\n",
      "27/100\n",
      "28/100\n",
      "29/100\n",
      "30/100\n",
      "31/100\n",
      "32/100\n",
      "33/100\n",
      "34/100\n",
      "35/100\n",
      "36/100\n",
      "37/100\n",
      "38/100\n",
      "39/100\n",
      "40/100\n",
      "41/100\n",
      "42/100\n",
      "43/100\n",
      "44/100\n",
      "45/100\n",
      "46/100\n",
      "47/100\n",
      "48/100\n",
      "49/100\n",
      "50/100\n",
      "51/100\n",
      "52/100\n",
      "53/100\n",
      "54/100\n",
      "55/100\n",
      "56/100\n",
      "57/100\n",
      "58/100\n",
      "59/100\n",
      "60/100\n",
      "61/100\n",
      "62/100\n",
      "63/100\n",
      "64/100\n",
      "65/100\n",
      "66/100\n",
      "67/100\n",
      "68/100\n",
      "69/100\n",
      "70/100\n",
      "71/100\n",
      "72/100\n",
      "73/100\n",
      "74/100\n",
      "75/100\n",
      "76/100\n",
      "77/100\n",
      "78/100\n",
      "79/100\n",
      "80/100\n",
      "81/100\n",
      "82/100\n",
      "83/100\n",
      "84/100\n",
      "85/100\n",
      "86/100\n",
      "87/100\n",
      "88/100\n",
      "89/100\n",
      "90/100\n",
      "91/100\n",
      "92/100\n",
      "93/100\n",
      "94/100\n",
      "95/100\n",
      "96/100\n",
      "97/100\n",
      "98/100\n",
      "99/100\n",
      "Test Accuracy : 0.0\n",
      "\n",
      "---------\n",
      "partype\n",
      "---------\n",
      "KNN\n",
      "Test Accuracy : 0.9062540786852872\n",
      "\n",
      "PCA+KNN\n",
      "Test Accuracy : 0.8436764063306871\n",
      "\n",
      "CORRELATION (on smaller dataset size=5000, test=100)\n",
      "0/100\n",
      "1/100\n",
      "2/100\n",
      "3/100\n",
      "4/100\n",
      "5/100\n",
      "6/100\n",
      "7/100\n",
      "8/100\n",
      "9/100\n",
      "10/100\n",
      "11/100\n",
      "12/100\n",
      "13/100\n",
      "14/100\n",
      "15/100\n",
      "16/100\n",
      "17/100\n",
      "18/100\n",
      "19/100\n",
      "20/100\n",
      "21/100\n",
      "22/100\n",
      "23/100\n",
      "24/100\n",
      "25/100\n",
      "26/100\n",
      "27/100\n",
      "28/100\n",
      "29/100\n",
      "30/100\n",
      "31/100\n",
      "32/100\n",
      "33/100\n",
      "34/100\n",
      "35/100\n",
      "36/100\n",
      "37/100\n",
      "38/100\n",
      "39/100\n",
      "40/100\n",
      "41/100\n",
      "42/100\n",
      "43/100\n",
      "44/100\n",
      "45/100\n",
      "46/100\n",
      "47/100\n",
      "48/100\n",
      "49/100\n",
      "50/100\n",
      "51/100\n",
      "52/100\n",
      "53/100\n",
      "54/100\n",
      "55/100\n",
      "56/100\n",
      "57/100\n",
      "58/100\n",
      "59/100\n",
      "60/100\n",
      "61/100\n",
      "62/100\n",
      "63/100\n",
      "64/100\n",
      "65/100\n",
      "66/100\n",
      "67/100\n",
      "68/100\n",
      "69/100\n",
      "70/100\n",
      "71/100\n",
      "72/100\n",
      "73/100\n",
      "74/100\n",
      "75/100\n",
      "76/100\n",
      "77/100\n",
      "78/100\n",
      "79/100\n",
      "80/100\n",
      "81/100\n",
      "82/100\n",
      "83/100\n",
      "84/100\n",
      "85/100\n",
      "86/100\n",
      "87/100\n",
      "88/100\n",
      "89/100\n",
      "90/100\n",
      "91/100\n",
      "92/100\n",
      "93/100\n",
      "94/100\n",
      "95/100\n",
      "96/100\n",
      "97/100\n",
      "98/100\n",
      "99/100\n",
      "Test Accuracy : 0.0\n",
      "\n",
      "---------\n",
      "tag\n",
      "---------\n",
      "KNN\n",
      "Test Accuracy : 0.8331725503770834\n",
      "\n",
      "PCA+KNN\n",
      "Test Accuracy : 0.7336951895631054\n",
      "\n",
      "CORRELATION (on smaller dataset size=5000, test=100)\n",
      "0/100\n",
      "1/100\n",
      "2/100\n",
      "3/100\n",
      "4/100\n",
      "5/100\n",
      "6/100\n",
      "7/100\n",
      "8/100\n",
      "9/100\n",
      "10/100\n",
      "11/100\n",
      "12/100\n",
      "13/100\n",
      "14/100\n",
      "15/100\n",
      "16/100\n",
      "17/100\n",
      "18/100\n",
      "19/100\n",
      "20/100\n",
      "21/100\n",
      "22/100\n",
      "23/100\n",
      "24/100\n",
      "25/100\n",
      "26/100\n",
      "27/100\n",
      "28/100\n",
      "29/100\n",
      "30/100\n",
      "31/100\n",
      "32/100\n",
      "33/100\n",
      "34/100\n",
      "35/100\n",
      "36/100\n",
      "37/100\n",
      "38/100\n",
      "39/100\n",
      "40/100\n",
      "41/100\n",
      "42/100\n",
      "43/100\n",
      "44/100\n",
      "45/100\n",
      "46/100\n",
      "47/100\n",
      "48/100\n",
      "49/100\n",
      "50/100\n",
      "51/100\n",
      "52/100\n",
      "53/100\n",
      "54/100\n",
      "55/100\n",
      "56/100\n",
      "57/100\n",
      "58/100\n",
      "59/100\n",
      "60/100\n",
      "61/100\n",
      "62/100\n",
      "63/100\n",
      "64/100\n",
      "65/100\n",
      "66/100\n",
      "67/100\n",
      "68/100\n",
      "69/100\n",
      "70/100\n",
      "71/100\n",
      "72/100\n",
      "73/100\n",
      "74/100\n",
      "75/100\n",
      "76/100\n",
      "77/100\n",
      "78/100\n",
      "79/100\n",
      "80/100\n",
      "81/100\n",
      "82/100\n",
      "83/100\n",
      "84/100\n",
      "85/100\n",
      "86/100\n",
      "87/100\n",
      "88/100\n",
      "89/100\n",
      "90/100\n",
      "91/100\n",
      "92/100\n",
      "93/100\n",
      "94/100\n",
      "95/100\n",
      "96/100\n",
      "97/100\n",
      "98/100\n",
      "99/100\n",
      "Test Accuracy : 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To start we will make sure we are using the same input data\n",
    "columns = [\"timeline.role\",\"timeline.lane\",\"partype\",\"tag\"]\n",
    "for col in columns:\n",
    "    print(\"---------\")\n",
    "    print(col)\n",
    "    print(\"---------\")\n",
    "    print(\"KNN\")\n",
    "    knn_pred = knn_predictor(x5,pd.DataFrame(y[col]),6) #as we saw it had more accuracy\n",
    "    knn_pred.accuracy() #the class already does does train/test splitting of the input dataset\n",
    "    print(\"\")\n",
    "    print(\"PCA+KNN\")\n",
    "    pca_mod = pca_and_knn(4,x5,y[col]) #we are reducing to 4 components\n",
    "    pca_mod.knn_accuracy()\n",
    "    print(\"\")\n",
    "    print(\"CORRELATION (on smaller dataset size=5000, test=100)\")\n",
    "    print(\"Test Accuracy : \"+format(testing_precision_corr_rec(x5[:5000],y[:5000],100,[col])))\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56f4995ff0f07fb23043dc681848bb9f3b1df43f8f1441a8a42cc2a23d5a426a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('projecte_dades_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
